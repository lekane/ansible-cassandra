
spark_version_main: spark-2.3.1
spark_version: "{{ spark_version_main }}-bin-hadoop2.7"
spark_url: "https://archive.apache.org/dist/spark/{{ spark_version_main }}/{{ spark_version }}.tgz"

spark_connector_name: spark-cassandra-connector_2.11-2.3.1.jar
spark_connector_url: "https://repo.maven.apache.org/maven2/com/datastax/spark/spark-cassandra-connector_2.11/2.3.1/{{ spark_connector_name }}"

spark_env:
  SPARK_CONF_DIR: /opt/spark/conf
  SPARK_LOG_DIR: /opt/spark/logs
  SPARK_PID_DIR: /opt/spark/pids
  SPARK_WORKER_DIR: /opt/spark/work
  SPARK_LOCAL_DIRS: /opt/spark/tmp
  SPARK_EXECUTOR_INSTANCES: "{{ executor_instances | default(1) }}"
  SPARK_WORKER_CORES: "{{ worker_cores | default(1) }}"
  SPARK_WORKER_MEMORY: "{{ worker_memory | default('1g') }}"
  SPARK_DRIVER_MEMORY: "{{ driver_memory | default('1g') }}"
  SPARK_REPL_MEM: 512m
  SPARK_WORKER_PORT: 9000
  SPARK_MASTER_OPTS: $LOG4J -Dspark.log.file=/opt/spark/logs/master.log
  SPARK_WORKER_OPTS: $LOG4J -Dspark.log.file=/opt/spark/logs/worker.log
  SPARK_EXECUTOR_OPTS: $LOG4J -Djava.io.tmpdir=/opt/spark/tmp/executor 
  SPARK_REPL_OPTS: -Djava.io.tmpdir=/opt/spark/tmp/repl/\$USER 
  SPARK_APP_OPTS: -Djava.io.tmpdir=/opt/spark/tmp/app/\$USER 

spark_defaults:
  #spark.serializer: org.apache.spark.serializer.KryoSerializer
  #spark.cores.max: 
  spark.executor.memory:  "{{ executor_memory }}"
  #spark.cassandra.input.consistency.level: LOCAL_QUORUM
  spark.cassandra.input.consistency.level: ONE
